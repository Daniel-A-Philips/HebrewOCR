{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Philipsd21/HebrewOCR/blob/main/OCR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test 1"
      ],
      "metadata": {
        "id": "oBHRs37q6YZH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_n6V6bqIKYSh"
      },
      "outputs": [],
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "!pip install opencv-contrib-python\n",
        "!pip3 install cropyble\n",
        "!apt-get install tesseract-ocr-heb\n",
        "!tesseract --list-langs\n",
        "!pip3 install openpyxl\n",
        "!pip install roman"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRIrBIcXV2tK"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ndMtYouKFaA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import pytesseract\n",
        "\n",
        "folderPath = \"/content/drive/MyDrive/Jastrow/Hebrewbooks_org_38236.zip (Unzipped Files)\"\n",
        "#folderPath = \"/content/Test_Data/\"\n",
        "myRevList = os.listdir(folderPath)\n",
        "print(len(myRevList))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWj1wuOuKIHY"
      },
      "outputs": [],
      "source": [
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openpyxl import load_workbook\n",
        "from pathlib import Path\n",
        "def get_headers():\n",
        "  path = Path('/content','drive','MyDrive','Copy of Headers.xlsx')\n",
        "  print(path)\n",
        "  wb = load_workbook(path)\n",
        "  sheet = wb.active\n",
        "  for row in sheet.iter_rows():\n",
        "    for cell in row:\n",
        "        value = cell.value\n",
        "        if value is None:\n",
        "          continue\n",
        "        else:\n",
        "          if len(value) == 1:\n",
        "            print(value)\n",
        "\n",
        "get_headers()"
      ],
      "metadata": {
        "id": "SZHABFnU3fri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search(word, to_search_in):\n",
        "  closest_word = difflib.get_close_matches(word, [], n=2)"
      ],
      "metadata": {
        "id": "FaiMJTiicyKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xST5x6CdKU2P"
      },
      "outputs": [],
      "source": [
        "from pytesseract.pytesseract import image_to_boxes\n",
        "from google.colab.patches import cv2_imshow\n",
        "import difflib\n",
        "import codecs\n",
        "import cv2\n",
        "completed_runs = 0\n",
        "run = 0\n",
        "corpus = []\n",
        "Pages = {}\n",
        "def threshold_test(image1):\n",
        "\n",
        " \n",
        "  # path to input image is specified and \n",
        "  # image is loaded with imread command  \n",
        "  # cv2.cvtColor is applied over the\n",
        "  # image input with applied parameters\n",
        "  # to convert the image in grayscale\n",
        "  img = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
        "  ret, thresh = cv2.threshold(img, 120, 255, cv2.THRESH_TOZERO)\n",
        "\n",
        "\n",
        "  return thresh\n",
        "\n",
        "def detect_words(img):\n",
        "  header_image = img[0:100, 0:1400]\n",
        "  left_image = header_image[0:100,200:474]\n",
        "  center_image = header_image[0:100, 475:925]\n",
        "  right_image = header_image[0:100, 925:1200]\n",
        "  return header_image, left_image, center_image, right_image\n",
        "\n",
        "def print_detected(thresholded):\n",
        "  for image in list(detect_words(thresholded))[1:]:\n",
        "    cv2_imshow(image)\n",
        "\n",
        "number_for_testing = 200\n",
        "pytesseract.pytesseract.tesseract_cmd = r\"/usr/bin/tesseract\"\n",
        "found_first_page, first_page_information = False, []\n",
        "for images in myRevList:\n",
        "    img = cv2.imread(f'{folderPath}/{images}')\n",
        "    if img is None: corpus.append(\"Could not read the image.\")\n",
        "    else:\n",
        "        run += 1\n",
        "        thresholded = threshold_test(img)\n",
        "        header_img, left_img, center_img, right_img = detect_words(thresholded)\n",
        "                \n",
        "        \n",
        "        center_ans = (pytesseract.image_to_string(center_img,lang='eng'))\n",
        "        left_ans = (pytesseract.image_to_string(left_img,lang='heb'))\n",
        "        right_ans = (pytesseract.image_to_string(right_img,lang='heb'))\n",
        "        answers = [center_ans, left_ans, right_ans]\n",
        "\n",
        "        for i in range(3): answers[i] = ''.join([character for character in answers[i] if character.isalnum()])\n",
        "        if (any([answer == '' in answer for answer in answers]) and not found_first_page):\n",
        "          continue\n",
        "        elif not found_first_page: first_page_information, found_first_page = [answers[0], run], True\n",
        "        completed_runs += 1\n",
        "        if completed_runs > number_for_testing:  break\n",
        "        #If the page number has returned an empty string, base it off of the previous pages number\n",
        "        if answers[0] == '':  answers[0] = (run - first_page_information[1]) + int(first_page_information[0])\n",
        "        \n",
        "        #Saving the pages information Pages[Page Number] = \n",
        "        Pages[answers[0]] = [answers[1], answers[2]]\n",
        "\n",
        "        print(f'{run}: {images}\\tLeft:{answers[1]}\\tCenter:{answers[0]}\\tRight:{answers[2]}')\n",
        "        #print_detected(thresholded)\n",
        "        cv2_imshow(detect_words(thresholded)[0])\n",
        "\n",
        "\n",
        "\n",
        "        corpus.append(0)\n",
        "\n",
        "print(Pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-8bQmQzZgxQ"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "\n",
        "def write_to_file(image_name, text):\n",
        "  if not os.path.exists('Text Files'):\n",
        "    os.makedirs('Text Files')\n",
        "  file = codecs.open('Text Files/'+str(image_name) + '.txt', \"w+\", \"utf-8\")\n",
        "  file.write(','.join(text))\n",
        "  file.close()\n",
        "\n",
        "def clear_files():\n",
        "    shutil.rmtree('Text Files')\n",
        "    os.makedirs('Text Files')\n",
        "\n",
        "clear_files()\n",
        "for i in list(Pages.keys()):\n",
        "  write_to_file(str(i),Pages[i])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test 2"
      ],
      "metadata": {
        "id": "aad0FXy86i7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_page_number(word,words_dictionary):\n",
        "  word_list = words_dictionary[word[0]]\n",
        "  print(word_list)\n"
      ],
      "metadata": {
        "id": "HGKByF0j7zd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A function to create the headers from the incomplete database\n",
        "# Only somewhat acurate\n",
        "\n",
        "from openpyxl import load_workbook\n",
        "from pathlib import Path\n",
        "\n",
        "words = {}\n",
        "all_words = []\n",
        "letters = []\n",
        "everything = []\n",
        "pages = {}\n",
        "def set_letters():\n",
        "  wb = load_workbook(Path('/content','drive','MyDrive','Copy of Headers.xlsx'))\n",
        "  sheet = wb.active\n",
        "  for row in sheet.iter_rows():\n",
        "    for cell in row:\n",
        "        value = cell.value\n",
        "        if value is None:\n",
        "          continue\n",
        "        else:\n",
        "          if len(value) == 1:\n",
        "            words[value] = []\n",
        "            letters.append(value)\n",
        "          else:\n",
        "            all_words.append(value)\n",
        "          everything.append(value)\n",
        "  for word in all_words:\n",
        "    print(word)\n",
        "    words[word[0]].append(word)\n",
        "set_letters()\n",
        "print(letters)\n",
        "is_on_new_page = {\n",
        "    'א':True\n",
        ", 'ב':False\n",
        ", 'ג':False\n",
        ", 'ד':False\n",
        ", 'ה':False\n",
        ", 'ו':False\n",
        ", 'ז':False\n",
        ", 'ח':False\n",
        ", 'ט':False\n",
        ", 'י':False\n",
        ", 'כ':False\n",
        ", 'ל':True\n",
        ", 'מ':False\n",
        ", 'נ':False\n",
        ", 'ס':True\n",
        ", 'ע':False\n",
        ", 'פ':False\n",
        ", 'צ':False\n",
        ", 'ק':False\n",
        ", 'ר':False\n",
        ", 'ש':True\n",
        ", 'ת':False\n",
        "    \n",
        "\n",
        "}\n",
        "\n",
        "print(is_on_new_page['ת'])"
      ],
      "metadata": {
        "id": "PO95bnnB6nUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_pages():\n",
        "  page = 1\n",
        "  to_add = []\n",
        "  for word in everything:\n",
        "    if len(word) == 1 and is_on_new_page[word]:\n",
        "      if len(to_add) != 0:\n",
        "        pages[page] = to_add\n",
        "        to_add = []\n",
        "        page += 1\n",
        "      pages[page] = word\n",
        "      page += 1\n",
        "      continue\n",
        "    to_add.append(word)      \n",
        "    if len(to_add) == 2:          \n",
        "      pages[page] = to_add\n",
        "      to_add = []\n",
        "      page += 1\n",
        "set_pages()\n",
        "print(pages)\n",
        "print(len(pages))"
      ],
      "metadata": {
        "id": "ROvmuKf0W279"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A function to find the minimum and maximum page that a word would how up in\n",
        "# word: A String of the word to be found\n",
        "# word_list: A dictionary of each starting word sorted by starting letter ['ת': ['תאוטני', 'תבה'\n",
        "def get_boundary_pages(word,word_list):\n",
        "  start_number = 0\n",
        "  for letter in word_list.keys():\n",
        "    if letter == word[0]:\n",
        "      break\n",
        "    start_number += len(word_list[letter])\n",
        "  start_number += list(word_list.keys()).index(word[0])\n",
        "\n",
        "  end_number = 0\n",
        "  next_letter = letters[letters.index(word[0]) + 1]\n",
        "  print(next_letter)\n",
        "  for letter in word_list.keys():\n",
        "    if letters[letters.index(letter)] == next_letter:\n",
        "      break\n",
        "    end_number += len(word_list[letter])\n",
        "  end_number += list(word_list.keys()).index(next_letter)\n",
        "  return start_number, end_number\n",
        "\n",
        "print(words)\n",
        "print(get_boundary_pages('ריסר',words))"
      ],
      "metadata": {
        "id": "aW-wjbKaBxwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test 3\n"
      ],
      "metadata": {
        "id": "otDtp6SRXilk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openpyxl import load_workbook\n",
        "from pathlib import Path\n",
        "searchable = []\n",
        "wb = load_workbook(Path('/content','drive','MyDrive','Copy of Headers.xlsx'))\n",
        "sheet = wb.active\n",
        "for row in sheet.iter_rows():\n",
        "  for cell in row:\n",
        "    if cell.value is not None:\n",
        "      searchable.append(cell.value) \n",
        "print(len(searchable))"
      ],
      "metadata": {
        "id": "qhnW2Ta-XvHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import roman\n",
        "word = input('enter your word:')\n",
        "\n",
        "for i in range (0,3):\n",
        "  r = requests.get(f'https://www.sefaria.org/Jastrow_אָמַר_{roman.toRoman(i)}')\n",
        "  print(r.content)"
      ],
      "metadata": {
        "id": "RQ2uuXBCXqj8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "aad0FXy86i7S",
        "otDtp6SRXilk"
      ],
      "name": "OCR",
      "provenance": [],
      "mount_file_id": "1HQhCOLc3t5AodOFU3yKSiIcNH2FX5w9v",
      "authorship_tag": "ABX9TyMxiROLrxNVeDJaNVuvRVVR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}